{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_Baseline.ipynb","provenance":[],"authorship_tag":"ABX9TyO0b6scjHoiP/c3As9UusMP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"uC6fcXiSTiSL","executionInfo":{"status":"ok","timestamp":1614096110674,"user_tz":-60,"elapsed":520,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["import torch.nn as nn\r\n","import torch\r\n","import copy\r\n","import torch.optim as optim\r\n","import torch.nn.functional as F\r\n","import math\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OS19zIMOXgYo"},"source":["Tagger"]},{"cell_type":"code","metadata":{"id":"F1YILdVbXikD","executionInfo":{"status":"ok","timestamp":1614096111250,"user_tz":-60,"elapsed":1083,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["class tag_Dataset():\r\n","\r\n","    def __init__(self, filename):\r\n","        self.filename = filename\r\n","\r\n","    def __iter__(self):\r\n","        tmp = []\r\n","        with open(self.filename, 'rt', encoding='utf-8') as lines:\r\n","            for line in lines:\r\n","                line = line.rstrip()\r\n","                if line:\r\n","                    tmp.append(tuple(line.split('\\t')))\r\n","                else:\r\n","                    yield tmp\r\n","                    tmp = []\r\n","\r\n","tag_train_data = tag_Dataset('train.txt')\r\n","tag_dev_data = tag_Dataset('dev.txt')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lkp6mOQ3YjO-","executionInfo":{"status":"ok","timestamp":1614096111251,"user_tz":-60,"elapsed":1074,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["def accuracy(tagger, gold_data):\r\n","    tp = 0\r\n","    total = 0\r\n","    for sentence in gold_data:\r\n","        tokens = []\r\n","        tags = []\r\n","        for pair in sentence:\r\n","            tokens.append(pair[0])\r\n","            tags.append(pair[1])\r\n","        for i, pred_tag in enumerate(tagger.predict(tokens)):\r\n","            if sentence[i][1] == pred_tag:\r\n","                tp += 1\r\n","            total += 1\r\n","    return tp/total"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKkJVnYaYuty","executionInfo":{"status":"ok","timestamp":1614096111251,"user_tz":-60,"elapsed":1066,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["PAD = '<pad>'\r\n","UNK = '<unk>'\r\n","def make_vocabs(gold_data):\r\n","    word_vocab = {PAD:0,UNK:1}\r\n","    tag_vocab = {PAD:0}\r\n","    inverse_word_vocab = {0:PAD,1:UNK}\r\n","    inverse_tag_vocab = {0:PAD}\r\n","    word_i = 2\r\n","    tag_i = 1\r\n","    for sentence in gold_data:\r\n","        for pair in sentence:\r\n","            if not (pair[0] in word_vocab):\r\n","                word_vocab[pair[0]] = word_i\r\n","                inverse_word_vocab[word_i] = pair[0]\r\n","                word_i += 1\r\n","            if not (pair[1] in tag_vocab):\r\n","                tag_vocab[pair[1]] = tag_i\r\n","                inverse_tag_vocab[tag_i] = pair[1]\r\n","                tag_i += 1\r\n","    return word_vocab, tag_vocab, inverse_word_vocab, inverse_tag_vocab\r\n","\r\n","vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags = make_vocabs(tag_train_data)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIgeM6quYyVd","executionInfo":{"status":"ok","timestamp":1614096111451,"user_tz":-60,"elapsed":1259,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["class tag_FixedWindowModel(nn.Module):\r\n","\r\n","    def __init__(self, embedding_specs = [(3, len(vocab_words), 50), (1, len(vocab_tags), 10)],\r\n","                 hidden_dim = 100, output_dim = len(vocab_tags)):\r\n","        super().__init__()\r\n","        embed_out_dim = 0\r\n","        embed_list = []\r\n","        n_cols = 0\r\n","        iters = []\r\n","        embed_i = 0\r\n","        for n, num_words, word_dim in embedding_specs:\r\n","            tmp_embedding_layer = nn.Embedding(num_words, word_dim)\r\n","            nn.init.normal_(tmp_embedding_layer.weight, std=0.01)\r\n","            embed_list.append(tmp_embedding_layer)\r\n","            embed_out_dim += word_dim * n\r\n","            iters += [embed_i] * n\r\n","            embed_i += 1\r\n","            n_cols += n\r\n","        self.iters = iters\r\n","        self.n_cols = n_cols\r\n","        self.embed = nn.ModuleList(embed_list)\r\n","        self.linear1 = nn.Linear(embed_out_dim, hidden_dim)\r\n","        self.relu = nn.ReLU()\r\n","        self.linear2 = nn.Linear(hidden_dim, output_dim)\r\n","\r\n","    def forward(self, features):\r\n","        if len(features.shape) == 1:\r\n","            features = torch.unsqueeze(features, dim=0)\r\n","        features = torch.cat(tuple(self.embed[self.iters[i]](features[:,i]) for i in range(self.n_cols)), 1)\r\n","        features = self.linear1(features)\r\n","        features = self.relu(features)\r\n","        features = self.linear2(features)\r\n","        return features"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qVJ47MxY6wl","executionInfo":{"status":"ok","timestamp":1614096111454,"user_tz":-60,"elapsed":1254,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["class Tagger(object):\r\n","\r\n","    def predict(self, sentence):\r\n","        raise NotImplementedError\r\n","\r\n","class FixedWindowTagger(Tagger):\r\n","\r\n","    def __init__(self, vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags, output_dim = 4, word_dim=50, tag_dim=10, hidden_dim=100):\r\n","        self.fw_model = tag_FixedWindowModel()\r\n","        self.vocab_words = vocab_words\r\n","        self.vocab_tags = vocab_tags\r\n","        self.inverse_vocab_words = inverse_vocab_words\r\n","        self.inverse_vocab_tags = inverse_vocab_tags\r\n","\r\n","    def featurize(self, words, i, pred_tags):\r\n","        tagger_conf = [0] * 4\r\n","        tagger_conf[0] = words[i]\r\n","        if i-1 < 0:\r\n","            tagger_conf[1] = self.vocab_words[PAD]\r\n","            tagger_conf[3] = self.vocab_tags[PAD]\r\n","        else:\r\n","            tagger_conf[1] = words[i-1]\r\n","            tagger_conf[3] = pred_tags[i-1]\r\n","        if i+1 > len(words)-1:\r\n","            tagger_conf[2] = self.vocab_words[PAD]\r\n","        else:\r\n","            tagger_conf[2] = words[i+1]\r\n","        return torch.LongTensor(tagger_conf)\r\n","\r\n","    def predict(self, words):\r\n","        pred_tag_ids = []\r\n","        word_ids = []\r\n","        for word in words:\r\n","\r\n","            word_ids.append(vocab_words[word] if word in vocab_words else vocab_words[UNK])\r\n","\r\n","        for i in range(len(word_ids)):\r\n","            window = self.featurize(word_ids, i, pred_tag_ids)\r\n","            pred = self.fw_model.forward(window)\r\n","            pred_tag_ids.append(torch.argmax(pred).item())\r\n","        pred_tags = []\r\n","        for tag_id in pred_tag_ids:\r\n","            pred_tags.append(inverse_vocab_tags[tag_id])\r\n","\r\n","        return pred_tags\r\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"2og4VB8WZGBX","executionInfo":{"status":"ok","timestamp":1614096111454,"user_tz":-60,"elapsed":1244,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["def tag_training_examples(vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags, gold_data, tagger, batch_size=100):\r\n","  batch_i = 0\r\n","  batch_x = torch.zeros((batch_size, 4), dtype=int)\r\n","  batch_y = torch.zeros(batch_size, dtype=int)\r\n","  for sentence in gold_data:\r\n","      word_ids = []\r\n","      tag_ids = []\r\n","      for pair in sentence:\r\n","          word_ids.append(vocab_words[pair[0]])\r\n","          tag_ids.append(vocab_tags[pair[1]])\r\n","      for i in range(len(word_ids)):\r\n","          if batch_i > batch_size - 1: \r\n","              yield batch_x, batch_y\r\n","              batch_x = torch.zeros((batch_size, 4), dtype=int)\r\n","              batch_y = torch.zeros(batch_size, dtype=int)\r\n","              batch_i = 0        \r\n","          batch_x[batch_i,:] = tagger.featurize(word_ids, i, tag_ids)\r\n","          batch_y[batch_i] = tag_ids[i]\r\n","          batch_i += 1\r\n","  if not batch_i == 0:\r\n","      yield batch_x[0:batch_i,:], batch_y[0:batch_i]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"-F3tPGCqZHIc","executionInfo":{"status":"ok","timestamp":1614096111455,"user_tz":-60,"elapsed":1236,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["def tag_train_fixed_window(train_data, n_epochs=2, batch_size=100, lr=1e-2):\r\n","    vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags = make_vocabs(train_data)\r\n","    fw_tagger = FixedWindowTagger(vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags)\r\n","    print(\"Vocabulary and model created!\")\r\n","    optimizer = optim.Adam(fw_tagger.fw_model.parameters(), lr=lr)\r\n","\r\n","    for ep in range(n_epochs):\r\n","        fw_tagger.fw_model.train()\r\n","        loss_sum = 0\r\n","        n_batch = 0\r\n","        for bx, by in tag_training_examples(vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags, train_data, fw_tagger, batch_size=batch_size):\r\n","            bx = bx.to(device)\r\n","            by = by.to(device)\r\n","            optimizer.zero_grad()\r\n","            output = fw_tagger.fw_model.forward(bx)\r\n","            loss = F.cross_entropy(output, by)\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","            loss_sum += loss.item()\r\n","            n_batch += 1      \r\n","        fw_tagger.fw_model.eval()\r\n","        print(\"Accuracy on validation data: \" + str(accuracy(fw_tagger, tag_dev_data)))\r\n","    return fw_tagger"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eRXLdbhyTjnP"},"source":["Parser"]},{"cell_type":"code","metadata":{"id":"uhs_UhL1Uh9l","executionInfo":{"status":"ok","timestamp":1614096111457,"user_tz":-60,"elapsed":1230,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["class Dataset():\r\n","\r\n","    ROOT = ('<root>', '<root>', 0)  # Pseudo-root\r\n","\r\n","    def __init__(self, filename):\r\n","        self.filename = filename\r\n","\r\n","    def __iter__(self):\r\n","        with open(self.filename, 'rt', encoding='utf-8') as lines:\r\n","            tmp = [Dataset.ROOT]\r\n","            for line in lines:\r\n","                if not line.startswith('#'):  # Skip lines with comments\r\n","                    line = line.rstrip()\r\n","                    if line:\r\n","                        columns = line.split('\\t')\r\n","                        if columns[0].isdigit():  # Skip range tokens\r\n","                            tmp.append((columns[1], columns[3], int(columns[6])))\r\n","                    else:\r\n","                        yield tmp\r\n","                        tmp = [Dataset.ROOT]\r\n","\r\n","parse_train_data = Dataset('en_ewt-ud-train-projectivized.conllu')\r\n","parse_dev_data = Dataset('en_ewt-ud-dev.conllu')"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaZeRBPolnbA","executionInfo":{"status":"ok","timestamp":1614096111457,"user_tz":-60,"elapsed":1221,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["def uas(parser, gold_data):\r\n","    tp = 0\r\n","    total = 0\r\n","    for sentence in gold_data:\r\n","        words, tags, heads = zip(*sentence)\r\n","        pred = parser.predict(words, tags)\r\n","        for i in range(1, len(pred)):\r\n","            if heads[i] == pred[i]:\r\n","                tp += 1\r\n","            total += 1\r\n","            #print(\"Iteration: \" + str(total) + \", UAS: \" + str(tp/total))\r\n","    return tp/total"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"3URwOrjjTnfw","executionInfo":{"status":"ok","timestamp":1614096111458,"user_tz":-60,"elapsed":1213,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["def oracle_moves(gold_heads):\r\n"," \r\n","    MOVES = tuple(range(3))\r\n","    SH, LA, RA = MOVES\r\n","\r\n","    parser = ArcStandardParser()\r\n","    config = parser.initial_config(len(gold_heads))\r\n","  \r\n","   \r\n","    while (not parser.is_final_config(config)):\r\n","        valid_moves = parser.valid_moves(config)\r\n","\r\n","        if len(valid_moves) >= 2:\r\n","            indices1 = [i for i, x in enumerate(gold_heads) if x == config[1][-2]]\r\n","            indices2 = [i for i, x in enumerate(config[2]) if x == config[1][-2]]\r\n","            indices3 = [i for i, x in enumerate(gold_heads) if x == config[1][-1]]\r\n","            indices4 = [i for i, x in enumerate(config[2]) if x == config[1][-1]]\r\n","            if LA in valid_moves and gold_heads[config[1][-2]] == config[1][-1] and all(item in indices2 for item in indices1):       \r\n","                yield (config, LA)\r\n","                config = parser.next_config(config, LA)\r\n","            elif ((RA in valid_moves) and (gold_heads[config[1][-1]] == config[1][-2]) and (all(item in indices4 for item in indices3))):\r\n","                yield (config, RA)\r\n","                config = parser.next_config(config, RA)\r\n","            else:\r\n","                yield (config, SH)\r\n","                config = parser.next_config(config, SH)\r\n","              \r\n","        else:\r\n","            yield (parser.next_config(config, SH), SH)\r\n","            config = parser.next_config(config, SH)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIFHKKhslrcx","executionInfo":{"status":"ok","timestamp":1614096111875,"user_tz":-60,"elapsed":1601,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["PAD = '<pad>'\r\n","UNK = '<unk>'\r\n","def make_vocabs(gold_data):\r\n","    # TODO: Replace the next line with your own code\r\n","    word_vocab = {PAD:0,UNK:1}\r\n","    tag_vocab = {PAD:0}\r\n","    inverse_word_vocab = {0:PAD,1:UNK}\r\n","    inverse_tag_vocab = {0:PAD}\r\n","    word_i = 2\r\n","    tag_i = 1\r\n","    for sentence in gold_data:\r\n","        for pair in sentence:\r\n","            if not (pair[0] in word_vocab):\r\n","                word_vocab[pair[0]] = word_i\r\n","                inverse_word_vocab[word_i] = pair[0]\r\n","                word_i += 1\r\n","            if not (pair[1] in tag_vocab):\r\n","                tag_vocab[pair[1]] = tag_i\r\n","                inverse_tag_vocab[tag_i] = pair[1]\r\n","                tag_i += 1\r\n","    return word_vocab, tag_vocab, inverse_word_vocab, inverse_tag_vocab\r\n","\r\n","vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags = make_vocabs(parse_train_data)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYNNXIecTzjo","executionInfo":{"status":"ok","timestamp":1614096111877,"user_tz":-60,"elapsed":1594,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["class Parser(object):\r\n","\r\n","    def predict(self, words, tags):\r\n","        raise NotImplementedError\r\n","\r\n","class ArcStandardParser(Parser):\r\n","\r\n","    MOVES = tuple(range(3))\r\n","\r\n","    SH, LA, RA = MOVES  # Parser moves are specified as integers.\r\n","\r\n","    @staticmethod\r\n","    def initial_config(num_words):\r\n","        return (0, [], [0]*num_words)\r\n","\r\n","    @staticmethod\r\n","    def valid_moves(config):\r\n","        valid_moves = []\r\n","        i, stack, head = config\r\n","        if i < len(head):\r\n","            valid_moves.append(0)\r\n","        if len(stack) >= 2:\r\n","            valid_moves.append(1)\r\n","            valid_moves.append(2)\r\n","        return valid_moves\r\n","\r\n","    @staticmethod\r\n","    def next_config(config, move):\r\n","        i, stack, head = config\r\n","        i, stack, head = copy.deepcopy(i), copy.deepcopy(stack), copy.deepcopy(head)\r\n","        if move == 0:\r\n","            stack.append(i)\r\n","            i += 1\r\n","            return (i, stack, head)\r\n","        if move == 1:\r\n","            head[stack[-2]] = stack[-1]\r\n","            del stack[-2]\r\n","            return (i, stack, head)\r\n","        if move == 2:\r\n","            head[stack[-1]] = stack[-2]\r\n","            del stack[-1]\r\n","            return (i, stack, head)\r\n","        print(\"Error!!!\")\r\n","\r\n","    @staticmethod\r\n","    def is_final_config(config):\r\n","        i, stack, head = config\r\n","\r\n","        if i == len(head) and len(stack) == 1:\r\n","            return True\r\n","        return False"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvpDr4ZfUfeF","executionInfo":{"status":"ok","timestamp":1614096111878,"user_tz":-60,"elapsed":1582,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["class parse_FixedWindowModel(nn.Module):\r\n","\r\n","    def __init__(self, embedding_specs = [(3, len(vocab_words), 50), (3, len(vocab_tags), 10)],\r\n","                 hidden_dim = 180, output_dim = 3):\r\n","        super().__init__()\r\n","        embed_out_dim = 0\r\n","        embed_list = []\r\n","        n_cols = 0\r\n","        iters = []\r\n","        embed_i = 0\r\n","        for n, num_words, word_dim in embedding_specs:\r\n","            tmp_embedding_layer = nn.Embedding(num_words, word_dim)\r\n","            nn.init.normal_(tmp_embedding_layer.weight, std=0.01)\r\n","            embed_list.append(tmp_embedding_layer)\r\n","            embed_out_dim += word_dim * n\r\n","            iters += [embed_i] * n\r\n","            embed_i += 1\r\n","            n_cols += n\r\n","        self.iters = iters\r\n","        self.n_cols = n_cols\r\n","        self.embed = nn.ModuleList(embed_list)\r\n","        self.linear1 = nn.Linear(embed_out_dim, hidden_dim)\r\n","        self.relu = nn.ReLU()\r\n","        self.linear2 = nn.Linear(hidden_dim, output_dim)\r\n","\r\n","    def forward(self, features):\r\n","        if len(features.shape) == 1:\r\n","            features = torch.unsqueeze(features, dim=0)\r\n","        features = torch.cat(tuple(self.embed[self.iters[i]](features[:,i]) for i in range(self.n_cols)), 1)\r\n","        features = self.linear1(features)\r\n","        features = self.relu(features)\r\n","        features = self.linear2(features)\r\n","        return features"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZAfA_zC_UubV","executionInfo":{"status":"ok","timestamp":1614096111880,"user_tz":-60,"elapsed":1570,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["class FixedWindowParser(ArcStandardParser):\r\n","\r\n","    def __init__(self, vocab_words, vocab_tags, hidden_dim=180):\r\n","        super().__init__()\r\n","        self.fw_model = parse_FixedWindowModel()\r\n","        self.vocab_words = vocab_words\r\n","        self.vocab_tags = vocab_tags\r\n"," \r\n","\r\n","    def featurize(self, words, tags, config):\r\n","        features = [0]*6\r\n","        i, stack, head = config\r\n","        i, stack, head = copy.deepcopy(i), copy.deepcopy(stack), copy.deepcopy(head)\r\n","        if i < len(words):\r\n","            features[0] = words[i]\r\n","            features[3] = tags[i]\r\n","        else:\r\n","            features[0] = self.vocab_words[PAD]\r\n","            features[3] = self.vocab_tags[PAD]\r\n","        if len(stack) == 0:\r\n","            features[1] = self.vocab_words[PAD]\r\n","            features[4] = self.vocab_tags[PAD]\r\n","        else:\r\n","            features[1] = words[stack[-1]]\r\n","            features[4] = tags[stack[-1]]\r\n","        if len(stack) <= 1:\r\n","            features[2] = self.vocab_words[PAD]\r\n","            features[5] = self.vocab_tags[PAD]\r\n","        else:\r\n","            features[2] = words[stack[-2]]\r\n","            features[5] = tags[stack[-2]]\r\n","\r\n","        return torch.LongTensor(features)\r\n","\r\n","\r\n","    def predict(self, words, tags, want_print = False):\r\n","        word_ids = []\r\n","        tag_ids = []\r\n","        for word in words:\r\n","            word_ids.append(self.vocab_words[word] if word in self.vocab_words else self.vocab_words[UNK])\r\n","        for tag in tags:\r\n","            tag_ids.append(self.vocab_tags[tag])\r\n","        config = self.initial_config(len(words))\r\n","        while not self.is_final_config(config):\r\n","            features = self.featurize(word_ids, tag_ids, config)\r\n","            pred = self.fw_model.forward(features)\r\n","            valid_moves = self.valid_moves(config)\r\n","\r\n","            best_move_score = -math.inf\r\n","            best_move = None\r\n","            for move in valid_moves:\r\n","                if pred[0,move].item() > best_move_score:\r\n","                    best_move = move\r\n","                    best_move_score = pred[0,move].item()\r\n","            if want_print:\r\n","                print(config)\r\n","            config = self.next_config(config, best_move)\r\n","        return config[2]"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4y8p_JijWlv","executionInfo":{"status":"ok","timestamp":1614096112405,"user_tz":-60,"elapsed":2077,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}},"outputId":"44f1841e-47ff-44b7-f9c5-56f4c0b6da47"},"source":["moves = [0, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2]    # 0 = SH, 1 = LA, 2 = RA\r\n","\r\n","parser = ArcStandardParser()\r\n","example_sentence = list(parse_train_data)[531]\r\n","config = parser.initial_config(len(example_sentence))\r\n","for move in moves:\r\n","    assert move in parser.valid_moves(config)\r\n","    config = parser.next_config(config, move)\r\n","assert parser.is_final_config(config)\r\n","assert config == (6, [0], [0, 2, 0, 4, 2, 2])\r\n","\r\n","\r\n","gold_heads = [h for w, t, h in example_sentence]\r\n","gold_moves = [0, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2]\r\n","\r\n","assert list(m for _, m in oracle_moves(gold_heads)) == gold_moves\r\n","\r\n","print('Looks good!')"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Looks good!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"--X3SGrMUwAK","executionInfo":{"status":"ok","timestamp":1614096112406,"user_tz":-60,"elapsed":2067,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["def parse_training_examples(vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags, gold_data, parser, batch_size=100):\r\n","  batch_i = 0\r\n","  batch_x = torch.zeros((batch_size, 6), dtype=int)\r\n","  batch_y = torch.zeros(batch_size, dtype=int)\r\n","  for sentence in gold_data:\r\n","      word_ids = []\r\n","      tag_ids = []\r\n","      heads = []\r\n","      for trip in sentence:\r\n","          word_ids.append(vocab_words[trip[0]])\r\n","          tag_ids.append(vocab_tags[trip[1]])\r\n","          heads.append(trip[2])\r\n","      \r\n","      for config, move in tuple(oracle_moves(heads))[1:]:\r\n","          if batch_i > batch_size - 1:\r\n","              yield batch_x, batch_y\r\n","              batch_x = torch.zeros((batch_size, 6), dtype=int)\r\n","              batch_y = torch.zeros(batch_size, dtype=int)\r\n","              batch_i = 0\r\n","          batch_x[batch_i,:] = parser.featurize(word_ids, tag_ids, config)\r\n","          batch_y[batch_i] = move \r\n","          batch_i += 1\r\n","  if not batch_i == 0:\r\n","      yield batch_x[0:batch_i,:], batch_y[0:batch_i]"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-DPPqLWU5GN","executionInfo":{"status":"ok","timestamp":1614096112603,"user_tz":-60,"elapsed":2257,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["def parse_train_fixed_window(train_data, n_epochs=2, batch_size=100, lr=1e-2):\r\n","    vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags = make_vocabs(train_data)\r\n","    parser = FixedWindowParser(vocab_words, vocab_tags)\r\n","    print(\"Vocabulary and model created!\")\r\n","    optimizer = optim.Adam(parser.fw_model.parameters(), lr=lr)\r\n","    \r\n","    for ep in range(n_epochs):\r\n","        parser.fw_model.train()\r\n","        n_batch = 0\r\n","        for bx, by in parse_training_examples(vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags, train_data, parser, batch_size=batch_size):\r\n","            #if n_batch > 10:\r\n","             #   break\r\n","            bx = bx.to(device)\r\n","            by = by.to(device)\r\n","            optimizer.zero_grad()\r\n","            output = parser.fw_model.forward(bx)\r\n","            loss = F.cross_entropy(output, by)\r\n","            loss.backward()\r\n","            optimizer.step()\r\n","            n_batch += 1\r\n","        parser.fw_model.eval()\r\n","    \r\n","    return parser"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5B7x0TZNVRMq"},"source":["Pipeline"]},{"cell_type":"code","metadata":{"id":"Yc17d2edZVNr","executionInfo":{"status":"ok","timestamp":1614096112603,"user_tz":-60,"elapsed":2249,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}}},"source":["\r\n"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qedZNVreWoi","executionInfo":{"status":"ok","timestamp":1614096267220,"user_tz":-60,"elapsed":156847,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}},"outputId":"0f0f31b4-d50e-4823-a819-8504c0a53f33"},"source":["vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags = make_vocabs(parse_train_data)\r\n","parser = parse_train_fixed_window(parse_train_data, n_epochs=1)\r\n","print('{:.4f}'.format(uas(parser, parse_dev_data)))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Vocabulary and model created!\n","0.7072\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeWpfu8wnefk","executionInfo":{"status":"ok","timestamp":1614096387894,"user_tz":-60,"elapsed":277514,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}},"outputId":"06ad9608-1d3e-4bb1-be41-dbcb52e5ec56"},"source":["vocab_words, vocab_tags, inverse_vocab_words, inverse_vocab_tags = make_vocabs(tag_train_data)\r\n","tagger = tag_train_fixed_window(tag_train_data, n_epochs=2)\r\n","print('{:.4f}'.format(accuracy(tagger, tag_dev_data)))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Vocabulary and model created!\n","Accuracy on validation data: 0.869850485128042\n","Accuracy on validation data: 0.8946238269444886\n","0.8946\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6t4nIBcAeXCv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614098187651,"user_tz":-60,"elapsed":39144,"user":{"displayName":"Martin Brolin","photoUrl":"","userId":"13874984341504961550"}},"outputId":"44ab6181-393c-4df4-ad5b-2c284681cc81"},"source":["pipeline_valid_data = []\r\n","for sentence in list(parse_dev_data):\r\n","    words = []\r\n","    heads = []\r\n","    for trip in sentence:\r\n","        words.append(trip[0])\r\n","        heads.append(trip[2])\r\n","    pred_tags = tagger.predict(words)\r\n","    valid_sentence = []\r\n","    for i in range(len(words)):\r\n","        valid_sentence.append((words[i], pred_tags[i], heads[i]))\r\n","    pipeline_valid_data.append(valid_sentence)\r\n","\r\n","print('{:.4f}'.format(uas(parser, pipeline_valid_data)))"],"execution_count":75,"outputs":[{"output_type":"stream","text":["0.6414\n"],"name":"stdout"}]}]}